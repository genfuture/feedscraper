name: Run News Scraper

on:
  schedule:
    - cron: '0 */8 * * *'  # Runs every 8 hours
  workflow_dispatch:  # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    # Check out the repository
    - uses: actions/checkout@v2
    
    # Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    
    # Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    # Run the scraper script
    - name: Run scraper
      run: python feed.py
    
    # Commit and push if changes
    - name: Commit and push if changes
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # Use the built-in GitHub token
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add -f new_articles.json new_articles.xml last_processed_links.json
        if ! git diff --quiet; then
          git commit -m "Update news articles [automated]"
          git push
        fi
