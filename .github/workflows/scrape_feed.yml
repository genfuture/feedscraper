name: Fetch and Track Latest Gadwal News Feed

on:
  schedule:
    # Runs every 6 hours
    - cron: "0 */6 * * *"
  workflow_dispatch: # Allows manual trigger

jobs:
  scrape-news:
    runs-on: ubuntu-latest

    steps:
    # Step 1: Checkout the repository
    - name: Checkout repository
      uses: actions/checkout@v3

    # Step 2: Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.9

    # Step 3: Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # Step 4: Run the feed scraper script
    - name: Run feed scraper
      run: |
        python feed.py

    # Step 5: Log the latest post
    - name: Display latest post
      run: |
        echo "Latest Post:" $(jq -r '.[0].title' new_articles.json)

    # Step 6: Commit and push updates
    - name: Commit and push updates
      run: |
        git config --global user.name "GitHub Actions"
        git config --global user.email "actions@github.com"
        git add .
        git commit -m "Update Gadwal News Feed [skip ci]" || echo "No changes to commit"
        git push
